{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TODO: Split Data into Train & Test_  \n",
    "_TODO: Review Word Embeddings_  \n",
    "\n",
    "\n",
    "- Build models that identify the category of a piece of text using binary categorization ✔️  \n",
    "- Use word embeddings in your TensorFlow model. ✔️  \n",
    "- Use LSTMs in your model to classify text for either binary or multi-class categorization.    \n",
    "- Add RNN and GRU layers to your model.\n",
    "- Use RNNS, LSTMs, GRUs and CNNs in models that work with text.\n",
    "- Train LSTMs on existing text to generate text (such as songs and poetry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: News Headline with Sarcasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data wrangling\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(edgeitems=10, linewidth=1000, formatter=dict(float=lambda x: \"%.3g\" % x))\n",
    "\n",
    "# preprocessing\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "# modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "## load data\n",
    "import os\n",
    "from pathlib import Path\n",
    "home = str(Path.home())\n",
    "base_dir = os.path.join(home, 'datasets/news-headlines-sarcasm')\n",
    "file_name = 'Sarcasm_Headlines_Dataset.json'\n",
    "json_file = os.path.join(base_dir, file_name)\n",
    "\n",
    "df = pd.read_json(json_file, lines=True)\n",
    "headlines = df.headline.to_list()\n",
    "true_values = df.is_sarcastic.to_list()\n",
    "\n",
    "## tokenize\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<UNK>')\n",
    "tokenizer.fit_on_texts(headlines)\n",
    "seq = tokenizer.texts_to_sequences(headlines)\n",
    "padded_sequences = pad_sequences(seq)\n",
    "\n",
    "true_values = np.array(true_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, ...,  679, 3337, 2298,   48,  382, 2576,    1,    6, 2577, 8434],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, ...,   22,    2,  166, 8436,  416, 3112,    6,  258,    9, 1002],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, ..., 1749, 2093,  582, 4719,  221,  143,   39,   46,    2,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, ...,    2, 1832,   29,  319,   22,   10, 2924, 1393, 6969,  968],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, ..., 4720,  908,    1,  623,  594,    5,    4,   95, 1309,   92],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, ...,    0,    0,    0,    0,    0,    0,    1,    4,  365,   73],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, ...,    0,    0,    4, 6970,  351,    6,  461, 4274, 2195, 1486],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, ...,   31,  155,    2,   99,   83,   18,  158,    6,   32,  352],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, ...,    0,    0,    0,  249, 3623, 6971,  555, 5274, 1995,  141],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, ...,    0, 2094,  326,  347,  401,   60,    1,    6,    4, 3896],\n",
       "       ...,\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, ...,   33,   18,  105,  589,   31,    1,  315, 1132,    2, 6918],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, ...,  511,    8,   33,    2,   93,   85, 4072, 2858,  471, 5429],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, ...,  266,  402,   11,   40,    3,    7, 3115,   14,   76,  217],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, ...,    2, 9008, 1001, 1728,   23,    3, 2164,    6,  113,  950],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, ...,    0,  297,  615,  608, 4192,    1,   34,  214,    6,  362],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, ...,    0,    0,    0,    0,  113,  689,    5, 3526,  288,  726],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, ...,    0,    0,    0,    0,    0,    0,  635,  102,  255,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, ...,    0,    0,    0,    0,    0,    0,    0,    1,    9,   68],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, ...,    0,    0, 1541,  392, 4164, 5634,  912, 1731, 3803, 3562],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, ...,    0,    0,    0,    0,    1, 1647,    6,    4,    1,  825]], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 40\n",
    "trunc_type = 'post'\n",
    "oov_tok = '<UNK>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 40, 16)            160000    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 3846      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 163,853\n",
      "Trainable params: 163,853\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=6, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26709 samples\n",
      "Epoch 1/4\n",
      "26709/26709 [==============================] - 4s 150us/sample - loss: 0.4378 - accuracy: 0.7849\n",
      "Epoch 2/4\n",
      "26709/26709 [==============================] - 3s 123us/sample - loss: 0.2268 - accuracy: 0.9112\n",
      "Epoch 3/4\n",
      "26709/26709 [==============================] - 3s 123us/sample - loss: 0.1409 - accuracy: 0.9492\n",
      "Epoch 4/4\n",
      "26709/26709 [==============================] - 3s 125us/sample - loss: 0.0758 - accuracy: 0.9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f96625d5b90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epoch = 10\n",
    "model.fit(padded_sequences,\n",
    "         true_values,\n",
    "         epochs=4\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
