{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_mnist = tfds.video.moving_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Datasets\n",
    "\n",
    "Listing with this command: `ds_list = tfds.list_builders()`\n",
    "\n",
    "More info: https://www.tensorflow.org/datasets/catalog/overview  \n",
    "\n",
    " - abstract_reasoning  \n",
    " - aeslc  \n",
    " - aflw2k3d  \n",
    " - amazon_us_reviews  \n",
    " - arc  \n",
    " - bair_robot_pushing_small  \n",
    " - beans  \n",
    " - big_patent  \n",
    " - bigearthnet  \n",
    " - billsum  \n",
    " - binarized_mnist  \n",
    " - binary_alpha_digits  \n",
    " - blimp  \n",
    " - c4  \n",
    " - caltech101  \n",
    " - caltech_birds2010  \n",
    " - caltech_birds2011  \n",
    " - cars196  \n",
    " - cassava  \n",
    " - cats_vs_dogs  \n",
    " - celeb_a  \n",
    " - celeb_a_hq  \n",
    " - cfq  \n",
    " - chexpert  \n",
    " - cifar10  \n",
    " - cifar100  \n",
    " - cifar10_1  \n",
    " - cifar10_corrupted  \n",
    " - citrus_leaves  \n",
    " - cityscapes  \n",
    " - civil_comments  \n",
    " - clevr  \n",
    " - cmaterdb  \n",
    " - cnn_dailymail  \n",
    " - coco  \n",
    " - coil100  \n",
    " - colorectal_histology  \n",
    " - colorectal_histology_large  \n",
    " - common_voice  \n",
    " - cos_e  \n",
    " - crema_d  \n",
    " - curated_breast_imaging_ddsm  \n",
    " - cycle_gan  \n",
    " - deep_weeds  \n",
    " - definite_pronoun_resolution  \n",
    " - dementiabank  \n",
    " - diabetic_retinopathy_detection  \n",
    " - div2k  \n",
    " - dmlab  \n",
    " - downsampled_imagenet  \n",
    " - dsprites  \n",
    " - dtd  \n",
    " - duke_ultrasound  \n",
    " - emnist  \n",
    " - eraser_multi_rc  \n",
    " - esnli  \n",
    " - eurosat  \n",
    " - fashion_mnist  \n",
    " - flic  \n",
    " - flores  \n",
    " - food101  \n",
    " - forest_fires  \n",
    " - gap  \n",
    " - geirhos_conflict_stimuli  \n",
    " - german_credit_numeric  \n",
    " - gigaword  \n",
    " - glue  \n",
    " - groove  \n",
    " - higgs  \n",
    " - horses_or_humans  \n",
    " - i_naturalist2017  \n",
    " - image_label_folder  \n",
    " - imagenet2012  \n",
    " - imagenet2012_corrupted  \n",
    " - imagenet2012_subset  \n",
    " - imagenet_resized  \n",
    " - imagenette  \n",
    " - imagewang  \n",
    " - imdb_reviews  \n",
    " - iris  \n",
    " - kitti  \n",
    " - kmnist  \n",
    " - lfw  \n",
    " - librispeech  \n",
    " - librispeech_lm  \n",
    " - libritts  \n",
    " - ljspeech  \n",
    " - lm1b  \n",
    " - lost_and_found  \n",
    " - lsun  \n",
    " - malaria  \n",
    " - math_dataset  \n",
    " - mnist  \n",
    " - mnist_corrupted  \n",
    " - movie_rationales  \n",
    " - moving_mnist  \n",
    " - multi_news  \n",
    " - multi_nli  \n",
    " - multi_nli_mismatch  \n",
    " - natural_questions  \n",
    " - newsroom  \n",
    " - nsynth  \n",
    " - omniglot  \n",
    " - open_images_challenge2019_detection  \n",
    " - open_images_v4  \n",
    " - opinosis  \n",
    " - oxford_flowers102  \n",
    " - oxford_iiit_pet  \n",
    " - para_crawl  \n",
    " - patch_camelyon  \n",
    " - pet_finder  \n",
    " - places365_small  \n",
    " - plant_leaves  \n",
    " - plant_village  \n",
    " - plantae_k  \n",
    " - qa4mre  \n",
    " - quickdraw_bitmap  \n",
    " - reddit  \n",
    " - reddit_tifu  \n",
    " - resisc45  \n",
    " - robonet  \n",
    " - rock_paper_scissors  \n",
    " - rock_you  \n",
    " - samsum  \n",
    " - savee  \n",
    " - scan  \n",
    " - scene_parse150  \n",
    " - scicite  \n",
    " - scientific_papers  \n",
    " - shapes3d  \n",
    " - smallnorb  \n",
    " - snli  \n",
    " - so2sat  \n",
    " - speech_commands  \n",
    " - squad  \n",
    " - stanford_dogs  \n",
    " - stanford_online_products  \n",
    " - starcraft_video  \n",
    " - stl10  \n",
    " - sun397  \n",
    " - super_glue  \n",
    " - svhn_cropped  \n",
    " - ted_hrlr_translate  \n",
    " - ted_multi_translate  \n",
    " - tedlium  \n",
    " - tf_flowers  \n",
    " - the300w_lp  \n",
    " - tiny_shakespeare  \n",
    " - titanic  \n",
    " - trivia_qa  \n",
    " - uc_merced  \n",
    " - ucf101  \n",
    " - vgg_face2  \n",
    " - visual_domain_decathlon  \n",
    " - voc  \n",
    " - voxceleb  \n",
    " - waymo_open_dataset  \n",
    " - web_questions  \n",
    " - wider_face  \n",
    " - wiki40b  \n",
    " - wikihow  \n",
    " - wikipedia  \n",
    " - wmt14_translate  \n",
    " - wmt15_translate  \n",
    " - wmt16_translate  \n",
    " - wmt17_translate  \n",
    " - wmt18_translate  \n",
    " - wmt19_translate  \n",
    " - wmt_t2t_translate  \n",
    " - wmt_translate  \n",
    " - xnli  \n",
    " - xsum  \n",
    " - yelp_polarity_reviews  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Dataset\n",
    "### A `Structured` Dataset\n",
    "German Credit Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, info = tfds.load('german_credit_numeric', split='train', shuffle_files=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='german_credit_numeric',\n",
       "    version=1.0.0,\n",
       "    description='This dataset classifies people described by a set of attributes as good or bad\n",
       "credit risks. The version here is the \"numeric\" variant where categorical and\n",
       "ordered categorical attributes have been encoded as indicator and integer\n",
       "quantities respectively.',\n",
       "    homepage='https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)',\n",
       "    features=FeaturesDict({\n",
       "        'features': Tensor(shape=(24,), dtype=tf.int32),\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
       "    }),\n",
       "    total_num_examples=1000,\n",
       "    splits={\n",
       "        'train': 1000,\n",
       "    },\n",
       "    supervised_keys=('features', 'label'),\n",
       "    citation=\"\"\"@misc{Dua:2019 ,\n",
       "    author = \"Dua, Dheeru and Graff, Casey\",\n",
       "    year = \"2017\",\n",
       "    title = \"{UCI} Machine Learning Repository\",\n",
       "    url = \"http://archive.ics.uci.edu/ml\",\n",
       "    institution = \"University of California, Irvine, School of Information and Computer Sciences\"\n",
       "    }\"\"\",\n",
       "    redistribution_info=,\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []\n",
    "for ex in tfds.as_numpy(ds):\n",
    "    features.append(ex['features'])\n",
    "    labels.append(ex['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 24)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other famous datasets:  \n",
    "\n",
    "* iris\n",
    "* titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, info = tfds.load('mnist', shuffle_files=True, with_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, info = tfds.load('tiny_shakespeare', shuffle_files=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='tiny_shakespeare',\n",
       "    version=1.0.0,\n",
       "    description='40,000 lines of Shakespeare from a variety of Shakespeare's plays. Featured in Andrej Karpathy's blog post 'The Unreasonable Effectiveness of Recurrent Neural Networks': http://karpathy.github.io/2015/05/21/rnn-effectiveness/.\n",
       "\n",
       "To use for e.g. character modelling:\n",
       "\n",
       "```\n",
       "d = tfds.load(name='tiny_shakespeare')['train']\n",
       "d = d.map(lambda x: tf.strings.unicode_split(x['text'], 'UTF-8'))\n",
       "# train split includes vocabulary for other splits\n",
       "vocabulary = sorted(set(next(iter(d)).numpy()))\n",
       "d = d.map(lambda x: {'cur_char': x[:-1], 'next_char': x[1:]})\n",
       "d = d.unbatch()\n",
       "seq_len = 100\n",
       "batch_size = 2\n",
       "d = d.batch(seq_len)\n",
       "d = d.batch(batch_size)\n",
       "```',\n",
       "    homepage='https://github.com/karpathy/char-rnn/blob/master/data/tinyshakespeare/input.txt',\n",
       "    features=FeaturesDict({\n",
       "        'text': Text(shape=(), dtype=tf.string),\n",
       "    }),\n",
       "    total_num_examples=3,\n",
       "    splits={\n",
       "        'test': 1,\n",
       "        'train': 1,\n",
       "        'validation': 1,\n",
       "    },\n",
       "    supervised_keys=None,\n",
       "    citation=\"\"\"@misc{\n",
       "      author={Karpathy, Andrej},\n",
       "      title={char-rnn},\n",
       "      year={2015},\n",
       "      howpublished={\\url{https://github.com/karpathy/char-rnn}}\n",
       "    }\"\"\",\n",
       "    redistribution_info=,\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tfds.load('tiny_shakespeare', split='train')\n",
    "ds = ds.take(1)\n",
    "\n",
    "text = []\n",
    "for s in tfds.as_numpy(ds):\n",
    "    text.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.decode(\"utf-8\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First Citizen:',\n",
       " 'Before we proceed any further, hear me speak.',\n",
       " '',\n",
       " 'All:',\n",
       " 'Speak, speak.',\n",
       " '',\n",
       " 'First Citizen:',\n",
       " 'You are all resolved rather to die than to famish?',\n",
       " '',\n",
       " 'All:',\n",
       " 'Resolved. resolved.',\n",
       " '',\n",
       " 'First Citizen:',\n",
       " 'First, you know Caius Marcius is chief enemy to the people.',\n",
       " '',\n",
       " 'All:',\n",
       " \"We know't, we know't.\",\n",
       " '',\n",
       " 'First Citizen:',\n",
       " \"Let us kill him, and we'll have corn at our own price.\"]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
